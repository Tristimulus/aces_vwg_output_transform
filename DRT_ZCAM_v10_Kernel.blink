
kernel DRT_ZCAM_v10_Kernel : ImageComputationKernel<ePixelWise>
{
  Image<eRead, eAccessPoint, eEdgeClamped> src; // the input image
  Image<eWrite> dst; // the output image

  param:
    //
    // Input Parameters
    //

    // Encoding of the Input Image
    // 0: Linear
    // 1: ACEScct
    // 2: sRGB
    // 3: BT.1886 (Gamma 2.4)
    // 4: Gamma 2.6
    // 5: ST2084
    int encodingIn;

    // Primaries of the Input Image
    // 0: AP0-ACES
    // 1: AP1-ACES
    // 2: sRGB/Rec.709-D65
    // 3: Rec.2020-D65
    // 4: P3-D65
    // 5: P3-DCI
    int primariesIn;

    //
    // ZCAM Paramters
    //

    // Chomatic Adaptation Transform to Use
    // 0: None
    // 1: XYZ Scaling
    // 2: Bradford
    // 3: CAT02
    // 4: Zhai2018 (two-step)
    int catType;

    // Disable Degree of Adaptation Model for Zhai2018 CAT
    // This is only effective if the limit primaries have a non-D65 white point
    // since the input conversion is assumed to be fully adapted
    // and the output conversion does not apply a CAT
    bool discountIlluminant;

    // Reference Luminance in Cd/sqm
    float referenceLuminance;

    // Background Luminance in Cd/sqm
    float backgroundLuminance;

    // Viewing Conditions (for output)
    // 0: Dark
    // 1: Dim
    // 2: Average
    int viewingConditions;

    //
    // SSTS Parameters
    //

    // Toggle SSTS Tone Mapping
    bool applySsts;
    
    // SSTS Luminances Min/Mid/Peak
    float3 sstsLuminance;

    // Toggle Highlight De-Saturation
    bool applyHighlightDesat;

    // Scale the De-Saturation Applied to the Highlights
    float desatHighlights;

    //
    // Gamut Mapping Parameters
    //

    // Primaries of the Target Gamut
    // 0: AP0-ACES
    // 1: AP1-ACES
    // 2: sRGB/Rec.709-D65
    // 3: Rec.2020-D65
    // 4: P3-D65
    // 5: P3-DCI
    int primariesLimit;


    // Toggle Gamut Compression
    bool applyGamutCompression;

    // Blend Between Compressing towards
    // Target Gamut Cusp Luminance (0.0)
    // and SSTS Mid Luminance (1.0)
    float cuspMidBlend;

    // the distance of the compression focal point
    // from the achromatic axis
    // normalised to the distance of the gamut cusp
    float focusDistance;

    // Gamut Compression Fuction Parameters
    // Threshold / Limit / Power
    float3 compressionFuncParams;

    // How much the edges of the target RGB cube are smoothed when finding the gamut boundary 
    // in order to reduce visible contours at the gamut cusps
    float smoothCusps;

    // When solving for the target gamut boundary
    // how many search interval halving steps to perform
    int boundarySolvePrecision;

    // Number of iterations to converge on the uncompressed J value 
    // Because of the compression focus point changes depending on the J value of the uncompressed sample
    // we cannot perfectly invert it since the original J value has now been changed by the forward compression
    // we can converge on a reasonable approximation of the original J value by iterating the inverse compression
    // although this is quite an expensive operation
    int inverseSolverIterations;

    //
    // Output Parameters
    //

    // Encoding of the Output Image
    // 0: Linear
    // 1: ACEScct
    // 2: sRGB
    // 3: BT.1886 (Gamma 2.4)
    // 4: Gamma 2.6
    // 5: ST2084
    int encodingOut;

    // Primaries of the Output Image
    // 0: AP0-ACES
    // 1: AP1-ACES
    // 2: sRGB/Rec.709-D65
    // 3: Rec.2020-D65
    // 4: P3-D65
    // 5: P3-DCI
    int primariesOut;

    // Clamp output values to 0.0 - 1.0
    bool clampOutput;

    //
    // Extra Parameters
    //

    // Toggle Inverse Transform
    bool invert;

  local:

    // constants
    float HALF_MIN;
    float HALF_MAX;

    // ZCAM vars
    float zcam_L_A;
    float zcam_F_b;
    float zcam_F_L;
    float zcam_cb;
    float zcam_cg;
    float zcam_c1;
    float zcam_c2;
    float zcam_c3;
    float zcam_eta;
    float zcam_rho;
    float zcam_luminance_shift;
    float zcam_viewing_conditions_coeff;

    // CAT vars
    float cat_adaptDegree;


    // ST2084 vars
    float st2084_m_1;
    float st2084_m_2;
    float st2084_c_1;
    float st2084_c_2;
    float st2084_c_3;
    float st2084_m_1_d;
    float st2084_m_2_d;
    float st2084_L_p;

    // SSTS constants
    float ssts_min_stop_sdr;
    float ssts_max_stop_sdr;
    float ssts_min_stop_rrt;
    float ssts_max_stop_rrt;
    float ssts_min_lum_sdr;
    float ssts_max_lum_sdr;
    float ssts_min_lum_rrt;
    float ssts_max_lum_rrt;
    int ssts_n_knots_low;
    int ssts_n_knots_high;
    float3x3 ssts_m1;

    // SSTS tables
    // using the float4 type to store the two 2D vectors
    // because Blink does not support generic array assignments
    float4 ssts_minTable;
    float4 ssts_maxTable;
    float4 ssts_bendsLow;
    float4 ssts_bendsHigh;

    // SSTS parameters
    float3 ssts_min_pt;
    float3 ssts_mid_pt;
    float3 ssts_max_pt;
    float ssts_knotIncLow;
    float ssts_knotIncHigh;
    float ssts_pctLow;
    float ssts_pctHigh;

    // using the float3x3 type to store the array of 6 coefficients
    // because Blink does not support generic array assignments
    float3x3 ssts_coefsLow;
    float3x3 ssts_coefsHigh;

    float ssts_expShift;
    float3 ssts_paramMin;
    float3 ssts_paramMid;
    float3 ssts_paramMax;


    // matrix vars
    float3x3 identity_matrix;
    float3x3 XYZ_to_LMS_Bradford;
    float3x3 XYZ_to_LMS_CAT02;
    float3x3 XYZ_to_LMS_ZCAM;
    float3x3 LMS_to_Izazbz;

    float3x3 XYZ_to_RGB_input;
    float3x3 XYZ_to_RGB_limit;
    float3x3 XYZ_to_RGB_output;

    float3x3 RGB_to_XYZ_input;
    float3x3 RGB_to_XYZ_limit;
    float3x3 RGB_to_XYZ_output;

    // white points
    float3 d65White;
    float3 inWhite;
    float3 refWhite;

    // the maximum RGB value of the limiting gamut
    float boundaryRGB;

    // the maximum lightness value of the limiting gamut
    float limitJmax;

    // the maximum colorfulness value of the limiting gamut
    float limitMmax;

    // the 1D LUT used for quickly findig the approximate limiting gamut cusp JMh coordinates
    // the samples are spaced by HSV hue increments of the limiting RGB gamut
    // so to find the correct entry for a given ZCAM hue (h) value 
    // one must search the table entries for the mathcing entry.z component
    int gamutCuspTableSize;

    // the 'gamutCuspTableUnsorted' table is populated
    // in increments of H of the limiting gamut HSV space starting at H=0.0
    // since it is unlikely that HSV.H=0 and JMh.h=0 line up
    // the entries are then wrap-around shifted
    // so that the 'gamutCuspTable' starts with the lowest JMh.h value
    // both tables need to be declared here since tempoary array variables
    // in the init() fuction seem to crash Nuke on some systems
    float3 gamutCuspTableUnsorted[360];
    float3 gamutCuspTable[360];

    // local version of the public focusDistance parameter
    // this one will be clamped to a value > 0.0
    float focusDistanceClamped;

  void define()
  {

  }

  // multiplies a 3D vector with a 3x3 matrix
  float3 vector_dot( float3x3 m, float3 v)
  {
    float3 r = 1.0f;
    for(int c = 0; c<3; c++)
    {
      r[c] = m[c][0]*v.x + m[c][1]*v.y + m[c][2]*v.z;
    }

    return r;
  }

  // linear interpolation between two values a & b with the bias t
  float lerp(float a, float b, float t)
  {
    return a + t * (b - a);
  }

  // get the y value of f(x) where the fuction is defined as a line between two points
  // the two points as passed as an array [a.x, a.y, b.x, b.y]
  float lerp1D( float4 table, float x)
  {
    float m = (table.w-table.y) / (table.z-table.x);
    float c = table.y - (m*table.x);
    float y = x*m+c;
    return y;
  }


  // "safe" power function to avoid NANs or INFs when taking a fractional power of a negative base
  // this one initially retured -pow(abs(b), e) for negative b
  // but this ended up producing undesirable results in some cases
  // so now it just returns 0.0 instead
  float spow( float base, float exponent )
  {
    if(base < 0.0f && exponent != floor(exponent) )
    {
      return 0.0f;
    }
    else
    {
     return pow(base, exponent); 
    }
  }


  // clamp the components of a 3D vector between a min & max value
  float3 clamp3(float3 v, float min, float max)
  {
    v.x = clamp(v.x, min, max);
    v.y = clamp(v.y, min, max);
    v.z = clamp(v.z, min, max);
    return v;
  }


  // convert radians to degrees
  float degrees( float radians )
  {
    return radians * 180.0f / PI;
  }


  // convert degrees to radians
  float radians( float degrees )
  {
    return degrees / 180.0f * PI;
  }


  // "PowerP" compression function (also used in the ACES Reference Gamut Compression transform)
  // values of v above  'treshold' are compressed by a 'power' function
  // so that an input value of 'limit' results in an output of 1.0
  float compressPowerP( float v, float threshold, float limit, float power, int inverse )
  {
    float s = (limit-threshold)/pow(pow((1.0f-threshold)/(limit-threshold),-power)-1.0f,1.0f/power);

    float vCompressed;

    if( inverse )
    {
      vCompressed = (v<threshold||limit<1.0001f||v>threshold+s)?v:threshold+s*pow(-(pow((v-threshold)/s,power)/(pow((v-threshold)/s,power)-1.0f)),1.0f/power);
    }
    else
    {
      vCompressed = (v<threshold||limit<1.0001f)?v:threshold+s*((v-threshold)/s)/(pow(1.0f+pow((v-threshold)/s,power),1.0f/power));
    }

    return vCompressed;
  }

  // Two-Stage chromatic adaptation transforms as proposed by  Zhai, Q., & Luo, M. R. (2018)
  // https://opg.optica.org/oe/fulltext.cfm?uri=oe-26-6-7724
  // https://github.com/colour-science/colour/blob/e5fa0790adcc3e5df5fa42ddf2bb75214c8cf59c/colour/adaptation/zhai2018.py
  float3 CAT_Zhai2018( float3 XYZ_b, float3 XYZ_wb, float3 XYZ_wd, float D_b, float D_d, float3x3 M)
  {
    float3 XYZ_wo = 100.0f;
    float3 RGB_b = vector_dot(M, XYZ_b);
    float3 RGB_wb = vector_dot(M, XYZ_wb);
    float3 RGB_wd = vector_dot(M, XYZ_wd);
    float3 RGB_wo = vector_dot(M, XYZ_wo);
    
    float3 D_RGB_b = D_b * (XYZ_wb.y / XYZ_wo.y) * (RGB_wo / RGB_wb) + 1 - D_b;
    float3 D_RGB_d = D_d * (XYZ_wd.y / XYZ_wo.y) * (RGB_wo / RGB_wd) + 1 - D_d;
    float3 D_RGB = D_RGB_b / D_RGB_d;
    
    float3 RGB_d = D_RGB * RGB_b;
    float3 XYZ_d = vector_dot(M.invert(), RGB_d);
    
    return XYZ_d;
  }

  // apply chromatic adaptation transform to 'XYZ' from 'XYZ_ws' to 'XYZ_wd' white points
  // 'type' selects the cone fundamentals matrix (exept for Zhai2018 which uses a 2-stage tranforms based on CATO2 fundamentals)
  // 'adaptDegree' sets the degree of adaptation for the Zhai2018 model
  float3 apply_CAT( float3 XYZ, float3 XYZ_ws, float3 XYZ_wd, int type, float adaptDegree )
  {
    float3x3 XYZ_to_LMS;

    if( type == 1 )
    {
      // XYZ Scaling
      XYZ_to_LMS = identity_matrix;
    }
    else if( type == 2 )
    {
      // Bradford
      XYZ_to_LMS = XYZ_to_LMS_Bradford;
    }
    else if( type == 3 )
    {
      // CAT02
      XYZ_to_LMS = XYZ_to_LMS_CAT02;
    }
    else if( type == 4 )
    {
      // Zhai2018
      return CAT_Zhai2018(XYZ, XYZ_ws, XYZ_wd, adaptDegree, adaptDegree, XYZ_to_LMS_CAT02);
    }
    else
    {
      // None
      return XYZ;
    }

    float3 LMS_ws = vector_dot(XYZ_to_LMS, XYZ_ws);
    float3 LMS_wd = vector_dot(XYZ_to_LMS, XYZ_wd);

    float3x3 Mscale = identity_matrix;
    Mscale[0][0] = LMS_wd.x / LMS_ws.x;
    Mscale[1][1] = LMS_wd.y / LMS_ws.y;
    Mscale[2][2] = LMS_wd.z / LMS_ws.z;

    float3x3 M = XYZ_to_LMS.invert() * Mscale * XYZ_to_LMS;

    return vector_dot(M, XYZ);
  }


  // convert XYZ tristimulus values to the ZCAM intermediate Izazbz colorspace
  float3 XYZ_to_Izazbz( float3 XYZD65 )
  {
    float3 XYZpD65 = XYZD65;
    XYZpD65.x = zcam_cb * XYZD65.x - (zcam_cb - 1.0f) * XYZD65.z;
    XYZpD65.y = zcam_cg * XYZD65.y - (zcam_cg - 1.0f) * XYZD65.x;
    float3 LMS = vector_dot(XYZ_to_LMS_ZCAM, XYZpD65);
    float3 LMSp = 0.0f;
    LMSp.x = spow( ( zcam_c1 + zcam_c2 * spow((LMS.x/10000.0f),zcam_eta) ) / ( 1.0f + zcam_c3 * spow((LMS.x/10000.0f),zcam_eta) ), zcam_rho);
    LMSp.y = spow( ( zcam_c1 + zcam_c2 * spow((LMS.y/10000.0f),zcam_eta) ) / ( 1.0f + zcam_c3 * spow((LMS.y/10000.0f),zcam_eta) ), zcam_rho);
    LMSp.z = spow( ( zcam_c1 + zcam_c2 * spow((LMS.z/10000.0f),zcam_eta) ) / ( 1.0f + zcam_c3 * spow((LMS.z/10000.0f),zcam_eta) ), zcam_rho);
    float3 Izazbz = vector_dot(LMS_to_Izazbz, LMSp);
    return Izazbz;
  }


  // convert the ZCAM intermediate Izazbz colorspace to XYZ tristimulus values
  float3 Izazbz_to_XYZ( float3 Izazbz )
  {
    float3 LMSp = vector_dot(LMS_to_Izazbz.invert(), Izazbz);
    float3 LMS = 0.0f;
    LMS.x = 10000.0f*spow((zcam_c1-spow(LMSp.x,1.0f/zcam_rho)) / (zcam_c3*spow(LMSp.x,1.0f/zcam_rho)-zcam_c2),1.0f/zcam_eta);
    LMS.y = 10000.0f*spow((zcam_c1-spow(LMSp.y,1.0f/zcam_rho)) / (zcam_c3*spow(LMSp.y,1.0f/zcam_rho)-zcam_c2),1.0f/zcam_eta);
    LMS.z = 10000.0f*spow((zcam_c1-spow(LMSp.z,1.0f/zcam_rho)) / (zcam_c3*spow(LMSp.z,1.0f/zcam_rho)-zcam_c2),1.0f/zcam_eta);
    float3 XYZpD65 = vector_dot(XYZ_to_LMS_ZCAM.invert(), LMS);
    float3 XYZD65 = XYZpD65;
    XYZD65.x = (XYZpD65.x+(zcam_cb-1.0f)*XYZpD65.z)/zcam_cb;
    XYZD65.y = (XYZpD65.y+(zcam_cg-1.0f)*XYZD65.x)/zcam_cg;
    return XYZD65;
  }


  // convert the ZCAM intermediate Izazbz colorspace to the ZCAM J (lightness), M (colorfulness) and h (hue) correlates
  // needs the Iz values of the reference white and the viewing conditions parameters
  float3 Izazbz_to_JMh( float3 Izazbz, float refWhiteIz, int viewingConditions )
  {
    float3 JMh = 0.0f;
    float zcam_F_s = zcam_viewing_conditions_coeff;

    JMh.z = fmod(degrees(atan2(Izazbz.z,Izazbz.y))+360.0f,360.0f);
    float ez = 1.015f + cos(radians(89.038f+JMh.z));
    float Qz  = 2700.0f * spow(Izazbz.x,   (1.6f * zcam_F_s) / pow(zcam_F_b, 0.12f)) * pow(zcam_F_s, 2.2f) * pow(zcam_F_b, 0.5f) * pow(zcam_F_L, 0.2f);
    float Qzw = 2700.0f * spow(refWhiteIz, (1.6f * zcam_F_s) / pow(zcam_F_b, 0.12f)) * pow(zcam_F_s, 2.2f) * pow(zcam_F_b, 0.5f) * pow(zcam_F_L, 0.2f);
    JMh.x = 100.0f * (Qz / Qzw);
    JMh.y = 100.0f * spow((spow(Izazbz.y, 2.0f) + spow(Izazbz.z, 2.0f)), 0.37f) * ((spow(ez, 0.068f) * pow(zcam_F_L, 0.2f)) / (pow(zcam_F_b, 0.1f) * pow(refWhiteIz, 0.78f)));

    return JMh;
  }


  // convert the ZCAM J (lightness), M (colorfulness) and h (hue) correlates to the ZCAM intermediate Izazbz colorspace
  // needs the Iz values of the reference white and the viewing conditions parameters
  float3 JMh_to_Izazbz( float3 JMh, float refWhiteIz, int viewingConditions )
  {
    float zcam_F_s = zcam_viewing_conditions_coeff;
    float Qzm = pow(zcam_F_s, 2.2f) * pow(zcam_F_b, 0.5f) * pow(zcam_F_L, 0.2f);
    float Qzw = 2700.0f * pow(refWhiteIz, (1.6f * zcam_F_s) / pow(zcam_F_b, 0.12f)) * Qzm;
    float Izp = pow(zcam_F_b, 0.12f) / (1.6f * zcam_F_s);
    float Izd = 2700.0f * 100.0f * Qzm;
    float ez = 1.015f + cos(radians(89.038f+JMh.z));
    float hzr = radians(JMh.z);
    float Czp = spow((JMh.y * pow(refWhiteIz, 0.78f) * pow(zcam_F_b, 0.1f)) / (100.0f * spow(ez, 0.068f) * pow(zcam_F_L, 0.2f)), 50.0f / 37.0f);

    return float3( spow((JMh.x * Qzw) / Izd, Izp), Czp * cos(hzr), Czp * sin(hzr));
  }


  // convert XYZ tristimulus values to the ZCAM J (lightness), M (colorfulness) and h (hue) correlates
  // needs XYZ tristimulus values for the reference white and a D65 white as well as the viewing conditions as parameters
  float3 XYZ_to_ZCAM_JMh( float3 XYZ, float3 refWhite, float3 d65White, int viewingConditions )
  {
    float3 refWhiteIzazbz = XYZ_to_Izazbz(refWhite*referenceLuminance/refWhite.y);
    return Izazbz_to_JMh(XYZ_to_Izazbz(apply_CAT(XYZ, refWhite, d65White, catType, cat_adaptDegree)), refWhiteIzazbz.x, viewingConditions);
  }


  // convert the ZCAM J (lightness), M (colorfulness) and h (hue) correlates to XYZ tristimulus values
  // needs XYZ tristimulus values for the reference white and a D65 white as well as the viewing conditions as parameters
  float3 ZCAM_JMh_to_XYZ( float3 JMh, float3 refWhite, float3 d65White, int viewingConditions )
  {
    float3 refWhiteIzazbz = XYZ_to_Izazbz(refWhite*referenceLuminance/refWhite.y);
    return apply_CAT(Izazbz_to_XYZ(JMh_to_Izazbz(JMh, refWhiteIzazbz.x, viewingConditions)), d65White, refWhite, catType, cat_adaptDegree);
  }


  // check if the 3D point 'v' is inside a cube with the dimensions cubeSize x cubeSize x cubeSize 
  // the 'smoothing' parameter rounds off the edges and corners of the cube with the exception of the 0,0,0 and cubeSize x cubeSize x cubeSize corners
  // a smoothing value of 0.0 applies no smoothing and 1.0 the maximum amount (smoothing values > 1.0 result in undefined behavior )
  int isInsideCube( float3 v, float cubeSize, float smoothing)
  {
    float3 normv = v / cubeSize;

    float minv = min(normv.x, min(normv.y, normv.z));
    float maxv = max(normv.x, max(normv.y, normv.z));

    if( smoothing <= 0.0f )
    {
      // when not smoothing we can use a much simpler test
      if(minv < 0.0f || maxv > 1.0f)
      {
        return 0;
      }

      return 1;
    }

    float3 clamped = normv;

    float radius = smoothing/2.0f;

    radius = clamp(radius*maxv*(1.0f-minv), 0.0f, radius);

    clamped.x = clamp(normv.x, radius, 1.0f-radius);
    clamped.y = clamp(normv.y, radius, 1.0f-radius);
    clamped.z = clamp(normv.z, radius, 1.0f-radius);


    if( length(normv - clamped ) > radius)
    {
      return 0;
    }

    return 1;
  }

  // convert ACEScct encoded values to linear
  float ACEScct_to_linear( float v )
  {
    return v > 0.155251141552511f ? pow( 2.0f, v * 17.52f - 9.72f) : (v - 0.0729055341958355f) / 10.5402377416545f;
  }

  // encode linear values as ACEScct
  float linear_to_ACEScct( float v )
  {
    return v > 0.0078125f ? (log2(v) + 9.72f) / 17.52f : 10.5402377416545f * v + 0.0729055341958355f;
  }


  // convert sRGB gamma encoded values to linear
  float sRGB_to_linear( float v )
  {
    return v < 0.04045f ? v / 12.92f : pow((v + 0.055f) / 1.055f, 2.4f);
  }

  // encode linear values as sRGB gamma
  float linear_to_sRGB( float v )
  {
    return v <= 0.0031308f ? 12.92f * v : 1.055 * (pow(v, 1.0f / 2.4f)) - 0.055f;
  }

  // convert ST2084 PQ encoded values to linear
  float ST2084_to_linear( float v )
  {
    float V_p = pow(v, st2084_m_2_d);
    return pow((max(0.0f, V_p - st2084_c_1) / (st2084_c_2 - st2084_c_3 * V_p)), st2084_m_1_d)*st2084_L_p;
  }

  // encode linear values as ST2084 PQ
  float linear_to_ST2084( float v )
  {
    float Y_p = pow(max(0.0f, v) / st2084_L_p, st2084_m_1);

    return pow((st2084_c_1 + st2084_c_2 * Y_p) / (st2084_c_3 * Y_p + 1.0f), st2084_m_2);
  }

  // decode value 'v' with the inverse of the selected encoding fuction to luminance
  float encodingToLuminance(int encoding, float v)
  {
    if( encoding == 1 )
    {
      // ACEScct
      return ACEScct_to_linear(v) * referenceLuminance;
    }
    else if( encoding == 2 )
    {
      // sRGB
      return sRGB_to_linear(v) * referenceLuminance;
    }
    else if( encoding == 3 )
    {
      // BT.1886 (Gamma 2.4)
      return pow(v, 2.4f) * referenceLuminance;
    }
    else if( encoding == 4 )
    {
      // Gamma 2.6
      return pow(v, 2.6f) * referenceLuminance;
    }
    else if( encoding == 5 )
    {
      // ST2084
      return ST2084_to_linear(v);
    }
    else
    {
      // Linear
      // default
      return v * referenceLuminance;
    }
  }

  // decode the components of a 3D vector 'v' with the inverse of the selected encoding fuction to luminance
  float3 encodingToLuminance3(int encoding, float3 v)
  {
    float3 lin;
    lin.x = encodingToLuminance(encoding, v.x);
    lin.y = encodingToLuminance(encoding, v.y);
    lin.z = encodingToLuminance(encoding, v.z);

    return lin;
  }

  // encode the linear luminance value 'v' with the encoding fuction selected by 'encoding'
  float luminanceToEncoding(int encoding, float v)
  {
    if( encoding == 1 )
    {
      // ACEScct
      return linear_to_ACEScct(v / referenceLuminance);
    }
    else if( encoding == 2 )
    {
      // sRGB
      return linear_to_sRGB(v / referenceLuminance);
    }
    else if( encoding == 3 )
    {
      // BT.1886 (Gamma 2.4)
      return pow(v / referenceLuminance, 1.0f/2.4f);
    }
    else if( encoding == 4 )
    {
      // Gamma 2.6
      return pow(v / referenceLuminance, 1.0f/2.6f);
    }
    else if( encoding == 5 )
    {
      // ST2084
      return linear_to_ST2084(v);
    }
    else
    {
      // Linear
      // default
      return v / referenceLuminance;
    }
  }

  // encode the linear luminance value components of a 3D vector 'v' with the encoding fuction selected by 'encoding'
  float3 luminanceToEncoding3(int encoding, float3 v)
  {
    float3 enc;
    enc.x = luminanceToEncoding(encoding, v.x);
    enc.y = luminanceToEncoding(encoding, v.y);
    enc.z = luminanceToEncoding(encoding, v.z);

    return enc;
  }


  // convert RGB values in the input colorspace to the ZCAM intermediate Izazbz colorspace
  float3 input_RGB_to_Izazbz(float3 inputRGB)
  {
    // clamp input to +/- HALF_MAX range (to remove inf values, etc.)
    inputRGB = clamp3(inputRGB, -HALF_MAX, HALF_MAX);

    // convert to linear XYZ luminance values
    float3 luminanceRGB = encodingToLuminance3( encodingIn, inputRGB);
    float3 luminanceXYZ = vector_dot(RGB_to_XYZ_input, luminanceRGB);

    // assuming 'fully adapted', dark' viewing conditions for input image (does that make sense?)
    return XYZ_to_Izazbz(apply_CAT(luminanceXYZ, inWhite, d65White, catType, 1.0f));
  }


  // convert values in the ZCAM intermediate Izazbz colorspace to RGB values in the input colorspace
  float3 Izazbz_to_input_RGB(float3 Izazbz)
  {
    float3 luminanceXYZ = Izazbz_to_XYZ(Izazbz);
    luminanceXYZ = apply_CAT(luminanceXYZ, d65White, inWhite, catType, 1.0f);
    float3 luminanceRGB = vector_dot(XYZ_to_RGB_input, luminanceXYZ);
    float3 RGB = luminanceToEncoding3(encodingIn, luminanceRGB);
    return RGB;
  }

  // convert RGB values in the output colorspace to the ZCAM J (lightness), M (colorfulness) and h (hue) correlates
  float3 output_RGB_to_JMh(float3 RGB)
  {
    float3 luminanceRGB = encodingToLuminance3(encodingOut, RGB);
    float3 XYZ = vector_dot(RGB_to_XYZ_output, luminanceRGB);
    float3 JMh = XYZ_to_ZCAM_JMh(XYZ, refWhite, d65White, viewingConditions);
    return JMh;
  }


  // convert ZCAM J (lightness), M (colorfulness) and h (hue) correlates to  RGB values in the output colorspace
  float3 JMh_to_output_RGB(float3 JMh)
  {
    float3 luminanceXYZ = ZCAM_JMh_to_XYZ( JMh, refWhite, d65White, viewingConditions );
    float3 luminanceRGB = vector_dot(XYZ_to_RGB_output, luminanceXYZ);
    float3 outputRGB = luminanceToEncoding3( encodingOut, luminanceRGB);

    if( clampOutput )
    {
      outputRGB = clamp3(outputRGB, 0.0f, 1.0f);
    }

    return outputRGB;
  }


  // convert linear RGB values with the limiting primaries to ZCAM J (lightness), M (colorfulness) and h (hue) correlates
  float3 limit_RGB_to_JMh(float3 RGB)
  {
    float3 luminanceRGB = RGB * boundaryRGB *referenceLuminance;
    float3 XYZ = vector_dot(RGB_to_XYZ_limit, luminanceRGB);
    float3 JMh = XYZ_to_ZCAM_JMh(XYZ, refWhite, d65White, viewingConditions);
    return JMh;
  }


  // convert ZCAM J (lightness), M (colorfulness) and h (hue) correlates to linear RGB values with the limiting primaries
  float3 JMh_to_limit_RGB(float3 JMh)
  {
    float3 luminanceXYZ = ZCAM_JMh_to_XYZ( JMh, refWhite, d65White, viewingConditions );
    float3 luminanceRGB = vector_dot(XYZ_to_RGB_output, luminanceXYZ);
    float3 RGB = luminanceRGB / boundaryRGB / referenceLuminance;
    return RGB;
  }


  // convert HSV cylindrical projection values to RGB
  float3 HSV_to_RGB( float3 HSV )
  {
    float C = HSV.z*HSV.y;
    float X = C*(1.0f-fabs(fmod(HSV.x*6.0f,2.0f)-1.0f));
    float m = HSV.z-C;

    float3 RGB;
    RGB.x = (HSV.x<1.0f/6.0f?  C :HSV.x<2.0f/6.0f?  X :HSV.x<3.0f/6.0f?0.0f:HSV.x<4.0f/6.0f?0.0f:HSV.x<5.0f/6.0f?  X :  C )+m;
    RGB.y = (HSV.x<1.0f/6.0f?  X :HSV.x<2.0f/6.0f?  C :HSV.x<3.0f/6.0f?  C :HSV.x<4.0f/6.0f?  X :HSV.x<5.0f/6.0f?0.0f:0.0f)+m;
    RGB.z = (HSV.x<1.0f/6.0f?0.0f:HSV.x<2.0f/6.0f?0.0f:HSV.x<3.0f/6.0f?  X :HSV.x<4.0f/6.0f?  C :HSV.x<5.0f/6.0f?  C :  X )+m;
    return RGB;
  }


  // convert RGB to HSV cylindrical projection values
  float3 RGB_to_HSV( float3 RGB )
  {
    float cmax = max(RGB.x,max(RGB.y,RGB.z));
    float cmin = min(RGB.x,min(RGB.y,RGB.z));
    float delta = cmax-cmin;

    float3 HSV;
    HSV.x = delta==0.0f?0.0f:cmax==RGB.x?(fmod((RGB.y-RGB.z)/delta+6.0f,6.0f))/6.0f:cmax==RGB.y?(((RGB.z-RGB.x)/delta+2.0f)/6.0f):(((RGB.x-RGB.y)/delta+4.0f)/6.0f);
    HSV.y = cmax == 0.0f ? 0.0f : delta / cmax;
    HSV.z = cmax;
    return HSV;
  }


  // retrieve the JM coordinates of the limiting gamut cusp at the hue slice 'h'
  // cusps are very expensive to compute
  // and the DRT is only using them for lightness mapping
  // which does not require a high degree of accuracy
  // so instead we use a pre-computed table of cusp points
  // sampled at 1 degree hue intervals of the the RGB target gamut
  // and lerp between them to get the approximate J & M values
  float2 cuspFromTable(float h)
  {

    float3 lo;
    float3 hi;

    if( h <= gamutCuspTable[0].z )
    {
      lo = gamutCuspTable[gamutCuspTableSize-1];
      lo.z = lo.z-360.0f;
      hi = gamutCuspTable[0];
    }
    else if( h >= gamutCuspTable[gamutCuspTableSize-1].z )
    {
      lo = gamutCuspTable[gamutCuspTableSize-1];
      hi = gamutCuspTable[0];
      hi.z = hi.z+360.f;
    }
    else
    {
      for(int i = 1; i < gamutCuspTableSize; ++i)
      {
        if( h <= gamutCuspTable[i].z )
        {
          lo = gamutCuspTable[i-1];
          hi = gamutCuspTable[i];
          break;
        }
      }
    }

    float t = (h - lo.z) / (hi.z - lo.z);

    float cuspJ = lerp(lo.x, hi.x, t);
    float cuspM = lerp(lo.y, hi.y, t);

    return float2(cuspJ,cuspM);
  }


  // find the JM coordinates of the smoothed boundary of the limiting gamaut in ZCAM at the hue slice 'h' 
  // by searching along the line defined by 'JMSource' and 'JMFocus'
  // the function will search outwards from where the line intersects the achromatic axis with a staring incement of 'startStepSize'
  // once the boundary has been crossed it will search in the opposite direction with half the step size
  // and will repeat this as as many times as is set by the 'precision' paramter
  float2 findBoundary(float2 JMSource, float2 JMFocus, float h, float3 XYZw, float3 XYZd65, float3x3 XYZ_to_RGB, float smoothing, int precision, float startStepSize )
  {

    float2 achromaticIntercept = float2(JMFocus.x - (((JMSource.x-JMFocus.x) / (JMSource.y-JMFocus.y))*JMFocus.y), 0.0f);

    if( achromaticIntercept.x <= 0.0f || achromaticIntercept.x >= limitJmax )
    {
       return achromaticIntercept;
    }


    float stepSize = startStepSize;
    float2 unitVector = normalize(achromaticIntercept - JMFocus);
    float2 JMtest = achromaticIntercept;
    int searchOutwards = 1;

    for( int i = 0; i < precision; ++i )
    {

      while( 1 )
      {
        JMtest = JMtest + unitVector * stepSize;
        int inside = isInsideCube( vector_dot(XYZ_to_RGB, ZCAM_JMh_to_XYZ( float3(JMtest.x, JMtest.y, h), XYZw, XYZd65, viewingConditions ) / referenceLuminance ), boundaryRGB, smoothing);

        if( searchOutwards )
        {
          if( JMtest.x < 0.0f || JMtest.x > limitJmax || JMtest.y > limitMmax || !inside )
          {
            searchOutwards = 0;
            stepSize = -fabs(stepSize) / 2.0f;
            break;
          }
        }
        else
        {
          if( JMtest.y < 0.0f || inside )
          {
            searchOutwards = 1;
            stepSize = fabs(stepSize) / 2.0f;
            break;
          }
        }
      }
    }


    float2 JMboundary = float2( clamp(JMtest.x, 0.0f, limitJmax), clamp(JMtest.y, 0.0f, limitMmax) );

    return JMboundary;
  }


  // apply the forward ACES SingleStageToneScale (SSTS) transfom to the linear 'x' input value and return a luminance value
  float forwardSSTS(float x, float3 minPt, float3 midPt, float3 maxPt)
  {
    // Check for negatives or zero before taking the log. If negative or zero,
    // set to HALF_MIN.
    float logx = log10( max(x, HALF_MIN )); 

    float logy;

    if( logx <= log10(minPt.x) )
    { 
        logy = logx * minPt.z + ( log10(minPt.y) - minPt.z * log10(minPt.x) );
    }
    else if(( logx > log10(minPt.x) ) && ( logx < log10(midPt.x) ))
    {
        float knot_coord = 3.0f * (logx-log10(minPt.x)) / (log10(midPt.x) - log10(minPt.x));
        int j = knot_coord;
        float t = knot_coord - float(j);
        float3 cf(ssts_coefsLow[j/3][j%3], ssts_coefsLow[(j+1)/3][(j+1)%3], ssts_coefsLow[(j+2)/3][(j+2)%3]);
        float3 monomials( t * t, t, 1.0f );
        logy = dot(monomials, vector_dot( ssts_m1, cf ));
    }
    else if(( logx >= log10(midPt.x) ) && ( logx < log10(maxPt.x) ))
    {
        float knot_coord = 3.0f * (logx-log10(midPt.x)) / (log10(maxPt.x) - log10(midPt.x));
        int j = knot_coord;
        float t = knot_coord - float(j);
        float3 cf(ssts_coefsHigh[j/3][j%3], ssts_coefsHigh[(j+1)/3][(j+1)%3], ssts_coefsHigh[(j+2)/3][(j+2)%3]); 
        float3 monomials(t * t, t, 1.0f);
        logy = dot(monomials, vector_dot( ssts_m1, cf ));
    }
    else
    {
        logy = logx * maxPt.z + ( log10(maxPt.y) - maxPt.z * log10(maxPt.x) );
    }

    return pow(10.0f,logy);
  }

  
  // apply the inverse ACES SingleStageToneScale (SSTS) transfomr to the 'x' luminance value and return an linear value
  float inverseSSTS(float y, float3 minPt, float3 midPt, float3 maxPt)
  {
    float KNOT_INC_LOW  = (log10(midPt.x) - log10(minPt.x)) / 3.0f;
    float KNOT_INC_HIGH = (log10(maxPt.x) - log10(midPt.x)) / 3.0f;

    // KNOT_Y is luminance of the spline at each knot
    float KNOT_Y_LOW[4];

   for( int i = 0; i < 4; i++ )
    {
      KNOT_Y_LOW[i] = ( ssts_coefsLow[i/3][i%3] + ssts_coefsLow[(i+1)/3][(i+1)%3]) / 2.0f;
    };

    float KNOT_Y_HIGH[ 4];

    for( int i = 0; i < 4; i++ )
    {
      KNOT_Y_HIGH[i] = ( ssts_coefsHigh[i/3][i%3] + ssts_coefsHigh[(i+1)/3][(i+1)%3]) / 2.0f;
    };

    float logy = log10( max(y, 0.0000000001f));

    float logx;

    if( logy <= log10(minPt.y) )
    {
        logx = log10(minPt.x);

    }
    else if( (logy > log10(minPt.y)) && (logy <= log10(midPt.y)) )
    {
        int j;
        float3 cf = 0.0f;

        if( logy > KNOT_Y_LOW[0] && logy <= KNOT_Y_LOW[1])
        {
          cf.x = ssts_coefsLow[0][0];
          cf.y = ssts_coefsLow[0][1];
          cf.z = ssts_coefsLow[0][2];
          j = 0;
        }
        else if( logy > KNOT_Y_LOW[1] && logy <= KNOT_Y_LOW[2])
        {
          cf.x = ssts_coefsLow[0][1];
          cf.y = ssts_coefsLow[0][2];
          cf.z = ssts_coefsLow[1][0];
          j = 1;
        }
        else if( logy > KNOT_Y_LOW[2] && logy <= KNOT_Y_LOW[3])
        {
          cf.x = ssts_coefsLow[0][2];
          cf.y = ssts_coefsLow[1][0];
          cf.z = ssts_coefsLow[1][1];
          j = 2;
        } 

        float3 tmp = vector_dot( ssts_m1, cf );

        float a = tmp.x;
        float b = tmp.y;
        float c = tmp.z;
        c = c - logy;

        float d = sqrt( b * b - 4.0f * a * c);

        float t = ( 2.0f * c) / ( -d - b);

        logx = log10(minPt.x) + ( t + j) * KNOT_INC_LOW;

    }
    else if( (logy > log10(midPt.y)) && (logy < log10(maxPt.y)) )
    {
        int j;
        float3 cf = 0.0f;

        if( logy >= KNOT_Y_HIGH[0] && logy <= KNOT_Y_HIGH[1])
        {
          cf.x = ssts_coefsHigh[0][0];
          cf.y = ssts_coefsHigh[0][1];
          cf.z = ssts_coefsHigh[0][2];
          j = 0;
        }
        else if( logy > KNOT_Y_HIGH[1] && logy <= KNOT_Y_HIGH[2])
        {
          cf.x = ssts_coefsHigh[0][1];
          cf.y = ssts_coefsHigh[0][2];
          cf.z = ssts_coefsHigh[1][0];
          j = 1;
        }
        else if( logy > KNOT_Y_HIGH[2] && logy <= KNOT_Y_HIGH[3])
        {
          cf.x = ssts_coefsHigh[0][2];
          cf.y = ssts_coefsHigh[1][0];
          cf.z = ssts_coefsHigh[1][1];
          j = 2;
        } 

        float3 tmp = vector_dot( ssts_m1, cf );

        float a = tmp.x;
        float b = tmp.y;
        float c = tmp.z;
        c = c - logy;

        float d = sqrt( b * b - 4.0f * a * c);

        float t = ( 2.0f * c) / ( -d - b);

        logx = log10(midPt.x) + ( t + j) * KNOT_INC_HIGH;

    }
    else
    {
        logx = log10(maxPt.x);

    }

    return pow(10.0f, logx);
  }


  // convert Iz to luminance
  // note that the PQ fuction used for Iz differs from the ST2084 function by replacing m_2 with rho
  // it also includes a luminance shift caused by the 2nd row-sum of the XYZ to LMS matrix not adding up to 1.0
  float IzToLuminance( float Iz )
  {
    float V_p = pow(Iz, 1.0f / zcam_rho);
    float luminance = pow((max(0.0f, V_p - st2084_c_1) / (st2084_c_2 - st2084_c_3 * V_p)), st2084_m_1_d)*st2084_L_p * zcam_luminance_shift;
    return luminance;
  }


  // convert luminance to Iz
  // note that the PQ fuction used for Iz differs from the ST2084 function by replacing m_2 with rho
  // it also includes a luminance shift caused by the 2nd row-sum of the XYZ to LMS matrix not adding up to 1.0
  float luminanceToIz( float luminance )
  {
    float Y_p = pow((luminance/zcam_luminance_shift) / st2084_L_p, st2084_m_1);
    float Iz = pow((st2084_c_1 + st2084_c_2 * Y_p) / (st2084_c_3 * Y_p + 1.0f), zcam_rho);
    return Iz;
  }


  // calculate a scale factor for colorfulness
  // based on the difference between the original and tone scaled (TS) Iz values
  // we are only interested in the differences above mid grey
  // so we first offset the original Iz values to align 18% it with the mid point of the IzTS value
  float highlightDesatFactor( float Iz, float IzTS )
  {

    float linear = IzToLuminance(Iz) / referenceLuminance;

    // no highlight desat below SSTS mid point
    if( linear < 0.18f )
    {
      return 1.0f;
    }

    float IzMid   = luminanceToIz(0.18f * referenceLuminance);
    float IzMidTS = luminanceToIz(sstsLuminance.y);

    float IzAligned = Iz + IzMidTS - IzMid;

    float desatFactor = 1.0f - clamp( compressPowerP( (log10(max(HALF_MIN, IzAligned)) - log10(max(HALF_MIN, IzTS))) * desatHighlights, compressionFuncParams.x, HALF_MAX, compressionFuncParams.z, 0 ), 0.0f, 1.0f);

    return desatFactor;
  }


  float3 forwardTonescale( float3 inputIzazbz )
  {
    float3 refWhiteIzazbz = XYZ_to_Izazbz(refWhite*referenceLuminance/refWhite.y);

    if( ! applySsts && ! applyHighlightDesat )
    {
      // nothing to do here except converting to JMh
      return Izazbz_to_JMh(inputIzazbz, refWhiteIzazbz.x, 0);
    }

    float linear = IzToLuminance(inputIzazbz.x) / referenceLuminance;
    float luminanceTS = forwardSSTS(linear, ssts_paramMin, ssts_paramMid, ssts_paramMax);
    float IzTS = luminanceToIz(luminanceTS);

    float3 outputIzazbz = inputIzazbz;

    if( applySsts )
    {
      outputIzazbz.x = IzTS;
    }

    // convert the result to JMh
    float3 outputJMh = Izazbz_to_JMh(outputIzazbz, refWhiteIzazbz.x, 0);

    if( applyHighlightDesat )
    {
      float factM = highlightDesatFactor(inputIzazbz.x, IzTS);
      outputJMh.y = outputJMh.y * factM;
    }

    return outputJMh;
  }


  float3 inverseTonescale( float3 JMh )
  {
    float3 refWhiteIzazbz = XYZ_to_Izazbz(refWhite*referenceLuminance/refWhite.y);
    float3 Izazbz = JMh_to_Izazbz(JMh, refWhiteIzazbz.x, 0);

    if( ! applySsts && ! applyHighlightDesat )
    {
      // nothing else to do here
      return Izazbz;
    }

    float luminance = IzToLuminance(Izazbz.x);
    float linear = inverseSSTS(luminance, ssts_paramMin, ssts_paramMid, ssts_paramMax);
    float Iz = luminanceToIz(linear*referenceLuminance);

    if( applyHighlightDesat )
    {
      float factM = highlightDesatFactor(Iz, Izazbz.x);
      JMh.y = JMh.y / factM;
      Izazbz = JMh_to_Izazbz(JMh, refWhiteIzazbz.x, 0);
      luminance = IzToLuminance(Izazbz.x);
      linear = inverseSSTS(luminance, ssts_paramMin, ssts_paramMid, ssts_paramMax);
      Iz = luminanceToIz(linear*referenceLuminance);
    }

    if( applySsts )
    {
      Izazbz.x = Iz;
    }

    return Izazbz;
  }


  // compress the ZCAM JM values into the limiting gamut by projecting them towards a focus point beyond the achromatic axis
  // in order to avoid the gamut compression to also compress black and white tones towards the focus point
  // (which would result in lifed blacks and crushed highlights)
  // we offset the focus further away from the achromatic axis the closer the lightness of a sample is to the zero or the limitJmax value
  // a far away focus point means the compression vector becomes close to orthogonal to the lightness axis preserving black & white lightness
  // the 'distanceGainCalcJ' paramter should be set to inputJMh.x for the forward direction
  // and to the best guess of the original, uncompressed values for the inverse direction
  // this is used for iteratively converging on the original, uncompressed value of J which would have gotten obfuscated by the forward transform
  float3 compressGamut( float3 inputJMh, int invert, float distanceGainCalcJ )
  {
    if( ! applyGamutCompression )
    {
      return inputJMh;
    }

    float sstsMidJ = XYZ_to_ZCAM_JMh( refWhite * sstsLuminance.y, refWhite, d65White, viewingConditions ).x;
    float2 JMinput = float2(inputJMh.x, inputJMh.y);
    float2 JMcusp = cuspFromTable( inputJMh.z);

    float focusJ = lerp(JMcusp.x, sstsMidJ, cuspMidBlend);

    float focusDistanceGain = 1.0f;

    if( distanceGainCalcJ > focusJ )
    {
      focusDistanceGain = (limitJmax - focusJ) / max(0.0001f, (limitJmax - min(limitJmax, distanceGainCalcJ)));
    }
    else
    {
      focusDistanceGain = (focusJ) / max(0.0001f, distanceGainCalcJ); 
    }

    float2 JMfocus = float2( focusJ, -JMcusp.y*focusDistanceClamped*focusDistanceGain );
    float2 vecToFocus = (JMfocus - JMinput);
    float2 achromaticIntercept = float2(JMfocus.x - (((JMinput.x-JMfocus.x) / (JMinput.y-JMfocus.y))*JMfocus.y), 0.0f);

    // to reduce the number of expensive boundary finding iterations needed
    // we taking an educated guess at a good starting step size
    // based on how far the sample is either above or below the gamut cusp
    float cuspToTipRatio;
    if( JMinput.x > JMcusp.x )
    {
      cuspToTipRatio = (JMinput.x - JMcusp.x) / (limitJmax - JMcusp.x);
    }
    else
    {
      cuspToTipRatio = (JMcusp.x - JMinput.x) / (JMcusp.x);
    }

    float startStepSize = lerp(JMcusp.y / 3.0f, 0.1f, cuspToTipRatio);
    float2 JMboundary = findBoundary(JMinput, JMfocus,  inputJMh.z, refWhite, d65White, XYZ_to_RGB_limit, smoothCusps, boundarySolvePrecision, startStepSize);
    float normFact = 1.0f / max(0.0001f, length(JMboundary - achromaticIntercept));
    float v = length(JMinput-achromaticIntercept) * normFact;
    float vCompressed = compressPowerP(v, compressionFuncParams.x, compressionFuncParams.y, compressionFuncParams.z, invert);
    float2 JMcompressed = achromaticIntercept + normalize(JMinput-achromaticIntercept)*vCompressed/normFact;
    return float3(JMcompressed.x, JMcompressed.y, inputJMh.z);
  }


  // apply the forward gamut compression to the limiting primaries
  float3 compressGamutForward( float3 JMh )
  {
    float3 JMhcompressed = compressGamut( JMh, 0, JMh.x );
    return JMhcompressed;
  }


  // apply the inverse gamut compression
  // and iterate a given number of times to reconstruct the original J value
  float3 compressGamutInverse( float3 JMh )
  {
    float3 JMhuncompressed;
    float distanceGainCalcJ = JMh.x;

    for( int i = 0; i < inverseSolverIterations; ++i )
    {
      JMhuncompressed = compressGamut( JMh, 1, distanceGainCalcJ );
      distanceGainCalcJ = JMhuncompressed.x;
    }

    return JMhuncompressed;
  }


  void init()
  {
    HALF_MIN = 0.0000000596046448f;
    HALF_MAX = 65504.0f;

    zcam_L_A = referenceLuminance * backgroundLuminance / 100.0f;
    zcam_F_b = sqrt(backgroundLuminance/referenceLuminance);
    zcam_F_L = 0.171f*pow(zcam_L_A, 1.0f/3.0f) * (1.0f-exp(-48.0f/9.0f*zcam_L_A));

    if( discountIlluminant )
    {
      cat_adaptDegree = 1.0f;
    }
    else
    {
      float viewingConditionsCoeff = 1.0f;

      if( viewingConditions == 0 )
      {
        viewingConditionsCoeff = 0.8f;
      }
      else if( viewingConditions == 1 )
      {
        viewingConditionsCoeff = 0.9f;
      }
      else if( viewingConditions == 2 )
      {
        viewingConditionsCoeff = 1.0f;
      }

      cat_adaptDegree = viewingConditionsCoeff * (1.0f - (1.0f / 3.6f) * exp((-zcam_L_A - 42.0f) / 92.0f));
    }

    zcam_cb  = 1.15f;
    zcam_cg  = 0.66f;
    zcam_c1  = 3424.0f / pow(2.0f,12.0f);
    zcam_c2  = 2413.0f / pow(2.0f, 7.0f);
    zcam_c3  = 2392.0f / pow(2.0f, 7.0f);
    zcam_eta = 2610.0f / pow(2.0f,14.0f);
    zcam_rho = 1.7f * 2523.0f / pow(2.0f,5.0f);
    zcam_luminance_shift = 1.0f / (-0.20151000f + 1.12064900f + 0.05310080f);

    zcam_viewing_conditions_coeff = 1.0f;

    if( viewingConditions == 0 )
    {
      zcam_viewing_conditions_coeff = 0.525f;
    }
    else if( viewingConditions == 1 )
    {
      zcam_viewing_conditions_coeff = 0.59f;
    }
    else if( viewingConditions == 2 )
    {
      zcam_viewing_conditions_coeff = 0.69f;
    }

    st2084_m_1=2610.0f / 4096.0f * (1.0f / 4.0f);
    st2084_m_2=2523.0f / 4096.0f * 128.0f;
    st2084_c_1=3424.0f / 4096.0f;
    st2084_c_2=2413.0f / 4096.0f * 32.0f;
    st2084_c_3=2392.0f / 4096.0f * 32.0f;
    st2084_m_1_d = 1.0f / st2084_m_1;
    st2084_m_2_d = 1.0f / st2084_m_2;
    st2084_L_p = 10000.0f;

    ssts_min_stop_sdr =  -6.5f;
    ssts_max_stop_sdr =   6.5f;
    ssts_min_stop_rrt = -15.0f;
    ssts_max_stop_rrt =  18.0f;
    ssts_min_lum_sdr = 0.02f;
    ssts_max_lum_sdr = 48.0f;
    ssts_min_lum_rrt = 0.0001f;
    ssts_max_lum_rrt = 10000.0f;
    ssts_n_knots_low = 4;
    ssts_n_knots_high = 4;

    ssts_minTable = float4(log10(ssts_min_lum_rrt), ssts_min_stop_rrt, log10(ssts_min_lum_sdr), ssts_min_stop_sdr);
    ssts_maxTable = float4(log10(ssts_max_lum_sdr), ssts_max_stop_sdr, log10(ssts_max_lum_rrt), ssts_max_stop_rrt);
    ssts_bendsLow = float4(ssts_min_stop_rrt, 0.18f, ssts_min_stop_sdr, 0.35f);
    ssts_bendsHigh = float4(ssts_max_stop_sdr, 0.89f, ssts_max_stop_rrt, 0.90f);

    float ssts_m1_data[]={ 0.5f,-1.0f, 0.5f,
                          -1.0f, 1.0f, 0.0f,
                           0.5f, 0.5f, 0.0f };
    ssts_m1.setArray(ssts_m1_data);

    ssts_min_pt.x = 0.18f * pow(2.0f, lerp1D(ssts_minTable, log10(sstsLuminance.x)));
    ssts_min_pt.y = sstsLuminance.x;
    ssts_min_pt.z = 0.0f;

    ssts_mid_pt = float3(0.18f, 4.8f, 1.55f);

    ssts_max_pt.x = 0.18f * pow(2.0f, lerp1D(ssts_maxTable, log10(sstsLuminance.z)));
    ssts_max_pt.y = sstsLuminance.z;
    ssts_max_pt.z = 0.0f;

    ssts_knotIncLow  = (log10(ssts_mid_pt.x) - log10(ssts_min_pt.x)) / 3.0f;
    ssts_knotIncHigh = (log10(ssts_max_pt.x) - log10(ssts_mid_pt.x)) / 3.0f;
    ssts_pctLow  = lerp1D(ssts_bendsLow,  log2(ssts_min_pt.x / 0.18f));
    ssts_pctHigh = lerp1D(ssts_bendsHigh, log2(ssts_max_pt.x / 0.18f));

    
    float ssts_coefsLow_data[] = {
      (ssts_min_pt.z * (log10(ssts_min_pt.x)-0.5f*ssts_knotIncLow)) + ( log10(ssts_min_pt.y) - ssts_min_pt.z * log10(ssts_min_pt.x)),
      (ssts_min_pt.z * (log10(ssts_min_pt.x)+0.5f*ssts_knotIncLow)) + ( log10(ssts_min_pt.y) - ssts_min_pt.z * log10(ssts_min_pt.x)),
      log10(ssts_min_pt.y) + ssts_pctLow*(log10(ssts_mid_pt.y)-log10(ssts_min_pt.y)),
      (ssts_mid_pt.z * (log10(ssts_mid_pt.x)-0.5f*ssts_knotIncLow)) + ( log10(ssts_mid_pt.y) - ssts_mid_pt.z * log10(ssts_mid_pt.x)),
      (ssts_mid_pt.z * (log10(ssts_mid_pt.x)+0.5f*ssts_knotIncLow)) + ( log10(ssts_mid_pt.y) - ssts_mid_pt.z * log10(ssts_mid_pt.x)),
      (ssts_mid_pt.z * (log10(ssts_mid_pt.x)+0.5f*ssts_knotIncLow)) + ( log10(ssts_mid_pt.y) - ssts_mid_pt.z * log10(ssts_mid_pt.x)),
      0.0f, 0.0f, 0.0f };

    float sssts_coefsHigh_data[] = {
      (ssts_mid_pt.z * (log10(ssts_mid_pt.x)-0.5f*ssts_knotIncHigh)) + ( log10(ssts_mid_pt.y) - ssts_mid_pt.z * log10(ssts_mid_pt.x)),
      (ssts_mid_pt.z * (log10(ssts_mid_pt.x)+0.5f*ssts_knotIncHigh)) + ( log10(ssts_mid_pt.y) - ssts_mid_pt.z * log10(ssts_mid_pt.x)),
      log10(ssts_mid_pt.y) + ssts_pctHigh*(log10(ssts_max_pt.y)-log10(ssts_mid_pt.y)),
      (ssts_max_pt.z * (log10(ssts_max_pt.x)-0.5f*ssts_knotIncHigh)) + ( log10(ssts_max_pt.y) - ssts_max_pt.z * log10(ssts_max_pt.x)),
      (ssts_max_pt.z * (log10(ssts_max_pt.x)+0.5f*ssts_knotIncHigh)) + ( log10(ssts_max_pt.y) - ssts_max_pt.z * log10(ssts_max_pt.x)),
      (ssts_max_pt.z * (log10(ssts_max_pt.x)+0.5f*ssts_knotIncHigh)) + ( log10(ssts_max_pt.y) - ssts_max_pt.z * log10(ssts_max_pt.x)),
      0.0f, 0.0f, 0.0f };

    ssts_coefsLow.setArray(ssts_coefsLow_data);
    ssts_coefsHigh.setArray(sssts_coefsHigh_data);

    ssts_paramMin = ssts_min_pt;
    ssts_paramMid = ssts_mid_pt;
    ssts_paramMax = ssts_max_pt;
    ssts_expShift = log2(inverseSSTS(sstsLuminance.y, ssts_min_pt, ssts_paramMid, ssts_max_pt)) - log2(0.18f);
    ssts_paramMin.x = pow(2.0f, (log(ssts_paramMin.x) / log(2.0f) - ssts_expShift));
    ssts_paramMid.x = pow(2.0f, (log(0.18f          ) / log(2.0f) - ssts_expShift));
    ssts_paramMax.x = pow(2.0f, (log(ssts_paramMax.x) / log(2.0f) - ssts_expShift));



    float identity_matrix_data[]={ 1.0f, 0.0f, 0.0f,
                                   0.0f, 1.0f, 0.0f,
                                   0.0f, 0.0f, 1.0f };

    float XYZ_to_LMS_Bradford_data[]={ 0.8951f, 0.2664f,-0.1614f,
                                      -0.7502f, 1.7135f, 0.0367f,
                                       0.0389f,-0.0685f, 1.0296f };

    float XYZ_to_LMS_CAT02_data[]={ 0.7328f, 0.4296f,-0.1624f,
                                   -0.7036f, 1.6975f, 0.0061f,
                                    0.0030f, 0.0136f, 0.9834f };

    float XYZ_to_LMS_ZCAM_data[]={ 0.41478972f, 0.57999900f, 0.01464800f,
                                  -0.20151000f, 1.12064900f, 0.05310080f,
                                  -0.01660080f, 0.26480000f, 0.66847990f };

    float eps = 3.7035226210190005e-11f;
    float LMS_to_Izazbz_data[]={ 0.000000f, 1.0f-eps , 0.000000f,
                                 3.524000f,-4.066708f, 0.542708f,
                                 0.199076f, 1.096799f,-1.295875f };


    identity_matrix.setArray(identity_matrix_data);
    XYZ_to_LMS_Bradford.setArray(XYZ_to_LMS_Bradford_data);
    XYZ_to_LMS_CAT02.setArray(XYZ_to_LMS_CAT02_data);
    XYZ_to_LMS_ZCAM.setArray(XYZ_to_LMS_ZCAM_data);
    LMS_to_Izazbz.setArray(LMS_to_Izazbz_data);


    // Blink does not seem to support initialising multidimensional arrays
    // So instead of being able to index the matrix data directly from one
    // we need to use long if/else statements to populate the
    // input, limit & output primary matrices
    // (maybe there is a better way?)

    float XYZ_to_AP0_ACES_matrix_data[]=
    {
       1.0498110175f,  0.0000000000f, -0.0000974845f,
      -0.4959030231f,  1.3733130458f,  0.0982400361f,
       0.0000000000f,  0.0000000000f,  0.9912520182f
    };

    float XYZ_to_AP1_ACES_matrix_data[]=
    {
       1.6410233797f, -0.3248032942f, -0.2364246952f,
      -0.6636628587f,  1.6153315917f,  0.0167563477f,
       0.0117218943f, -0.0082844420f,  0.9883948585f,
    };

    float XYZ_to_Rec709_D65_matrix_data[]=
    {
       3.2409699419f, -1.5373831776f, -0.4986107603f,
      -0.9692436363f,  1.8759675015f,  0.0415550574f,
       0.0556300797f, -0.2039769589f,  1.0569715142f,
    };

    float XYZ_to_Rec2020_D65_matrix_data[]=
    {
       1.7166511880f, -0.3556707838f, -0.2533662814f,
      -0.6666843518f,  1.6164812366f,  0.0157685458f,
       0.0176398574f, -0.0427706133f,  0.9421031212f,
    };

    float XYZ_to_P3_D65_matrix_data[]=
    {
       2.4934969119f, -0.9313836179f, -0.4027107845f,
      -0.8294889696f,  1.7626640603f,  0.0236246858f,
       0.0358458302f, -0.0761723893f,  0.9568845240f,
    };

    float XYZ_to_P3_DCI_matrix_data[]=
    {
       2.7253940305f, -1.0180030062f, -0.4401631952f,
      -0.7951680258f,  1.6897320548f,  0.0226471906f,
       0.0412418914f, -0.0876390192f,  1.1009293786f
    };

    // populate the input primaries matrix
    if( primariesIn == 0 )
    {
      XYZ_to_RGB_input.setArray(XYZ_to_AP0_ACES_matrix_data);
    }
    else if( primariesIn == 1 )
    {
      XYZ_to_RGB_input.setArray(XYZ_to_AP1_ACES_matrix_data);
    }
    else if( primariesIn == 2 )
    {
      XYZ_to_RGB_input.setArray(XYZ_to_Rec709_D65_matrix_data);
    }
    else if( primariesIn == 3 )
    {
      XYZ_to_RGB_input.setArray(XYZ_to_Rec2020_D65_matrix_data);
    }
    else if( primariesIn == 4 )
    {
      XYZ_to_RGB_input.setArray(XYZ_to_P3_D65_matrix_data);
    }
    else if( primariesIn == 5 )
    {
      XYZ_to_RGB_input.setArray(XYZ_to_P3_DCI_matrix_data);
    }
    else
    {
      XYZ_to_RGB_input.setArray(identity_matrix_data);
    }

    // populate the limiting primaries matrix
    if( primariesLimit == 0 )
    {
      XYZ_to_RGB_limit.setArray(XYZ_to_AP0_ACES_matrix_data);
    }
    else if( primariesLimit == 1 )
    {
      XYZ_to_RGB_limit.setArray(XYZ_to_AP1_ACES_matrix_data);
    }
    else if( primariesLimit == 2 )
    {
      XYZ_to_RGB_limit.setArray(XYZ_to_Rec709_D65_matrix_data);
    }
    else if( primariesLimit == 3 )
    {
      XYZ_to_RGB_limit.setArray(XYZ_to_Rec2020_D65_matrix_data);
    }
    else if( primariesLimit == 4 )
    {
      XYZ_to_RGB_limit.setArray(XYZ_to_P3_D65_matrix_data);
    }
    else if( primariesLimit == 5 )
    {
      XYZ_to_RGB_limit.setArray(XYZ_to_P3_DCI_matrix_data);
    }
    else
    {
      XYZ_to_RGB_limit.setArray(identity_matrix_data);
    }

    // populate the output primaries matrix
    if( primariesOut == 0 )
    {
      XYZ_to_RGB_output.setArray(XYZ_to_AP0_ACES_matrix_data);
    }
    else if( primariesOut == 1 )
    {
      XYZ_to_RGB_output.setArray(XYZ_to_AP1_ACES_matrix_data);
    }
    else if( primariesOut == 2 )
    {
      XYZ_to_RGB_output.setArray(XYZ_to_Rec709_D65_matrix_data);
    }
    else if( primariesOut == 3 )
    {
      XYZ_to_RGB_output.setArray(XYZ_to_Rec2020_D65_matrix_data);
    }
    else if( primariesOut == 4 )
    {
      XYZ_to_RGB_output.setArray(XYZ_to_P3_D65_matrix_data);
    }
    else if( primariesOut == 5 )
    {
      XYZ_to_RGB_output.setArray(XYZ_to_P3_DCI_matrix_data);
    }
    else
    {
      XYZ_to_RGB_output.setArray(identity_matrix_data);
    }

    RGB_to_XYZ_input = XYZ_to_RGB_input.invert();
    RGB_to_XYZ_limit = XYZ_to_RGB_limit.invert();
    RGB_to_XYZ_output = XYZ_to_RGB_output.invert();


    float3x3 XYZ_to_RGB_sRGB;
    XYZ_to_RGB_sRGB.setArray(XYZ_to_Rec709_D65_matrix_data);
    float3 white(1.0f, 1.0f, 1.0f);

    d65White = vector_dot(XYZ_to_RGB_sRGB.invert(), white);
    inWhite = vector_dot(RGB_to_XYZ_input, white);
    refWhite = vector_dot(RGB_to_XYZ_limit, white);

    boundaryRGB = sstsLuminance.z / referenceLuminance;


    //
    // solving the RGB cusp from JMh is very expensive
    // instead we go the other way and start with a RGB cusp sweep
    // which is easily calculated by converting via HSV (Hue, 1.0, 1.0)
    // we then convert each cusp to JMh and add them to a table 
    //

    gamutCuspTableSize = 360;

    for( int i = 0; i < gamutCuspTableSize; ++i )
    {
      float hNorm = float(i) / (gamutCuspTableSize);
      float3 RGB = HSV_to_RGB(float3(hNorm, 1.0f, 1.0f));
      gamutCuspTableUnsorted[i] = limit_RGB_to_JMh(RGB);
    }

    int minhIndex = 0;
    for( int i = 1; i < gamutCuspTableSize; ++i )
    {
      if( gamutCuspTableUnsorted[i].z <  gamutCuspTableUnsorted[minhIndex].z)
      {
        minhIndex = i;
      }
    }


    for( int i = 0; i < gamutCuspTableSize; ++i )
    {
      gamutCuspTable[i] = gamutCuspTableUnsorted[(minhIndex+i)%gamutCuspTableSize];
      
    }

    // calculate the maximum expected J & M values for the given limit gamut
    // these are used as limiting values for the gamut boundary searches

    // limitJmax (asumed to match limitRGB white)
    limitJmax = limit_RGB_to_JMh(float3(1.0f)).x;


    // limitMmax (asumed to coincide with one of the RGBCMY corners of the limitRGB cube)
    float3 gamutCornersTable[6];
    gamutCornersTable[0] = limit_RGB_to_JMh(float3(1.0f, 0.0f, 0.0f));
    gamutCornersTable[1] = limit_RGB_to_JMh(float3(1.0f, 1.0f, 0.0f));
    gamutCornersTable[2] = limit_RGB_to_JMh(float3(0.0f, 1.0f, 0.0f));
    gamutCornersTable[3] = limit_RGB_to_JMh(float3(0.0f, 1.0f, 1.0f));
    gamutCornersTable[4] = limit_RGB_to_JMh(float3(0.0f, 0.0f, 1.0f));
    gamutCornersTable[5] = limit_RGB_to_JMh(float3(1.0f, 0.0f, 1.0f));

    limitMmax = 0.0f;
    for( int i = 0; i < 6; ++i )
    {
      limitMmax = max(limitMmax, gamutCornersTable[i].y);
    }

    // ensure positive, non-zero focus depth
    // to avoid the gamut boundary search vector becoming zero for achromatic colors
    // which will cause the boundary search loop to continue forever and the node to hang
    focusDistanceClamped = max(0.01f, focusDistance);
  }


  void process()
  {
    SampleType(src) source = src();
    float3 srcRGB(source.x, source.y, source.z);
    float3 dstRGB;

    if( invert )
    {
      float3 JMh = output_RGB_to_JMh(srcRGB);
      JMh = compressGamutInverse(JMh);
      float3 inputIzazbz = inverseTonescale(JMh);
      dstRGB = Izazbz_to_input_RGB(inputIzazbz);
    }
    else
    {
      float3 inputIzazbz = input_RGB_to_Izazbz(srcRGB);
      float3 JMh = forwardTonescale(inputIzazbz);
      JMh = compressGamutForward(JMh);
      dstRGB = JMh_to_output_RGB(JMh);
    }

    dst() = float4(dstRGB.x, dstRGB.y, dstRGB.z, source.w); 
  }
};
